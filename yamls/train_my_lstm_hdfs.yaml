name: ailab-shikang-tf-yt8m-frame-level-my-lstm
owner: shikang@bytedance.com
disable_timestamp_on_name: 1
repos:
    tf-youtube-8m: git@code.byted.org:lab/tf-youtube-8m.git#shikang

cpus: 4
mem: 32768
disk: 2548000
gpus: 4

sh: >
    source /opt/tiger/keras2/bin/activate;
    export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH;
    ROOT_DIR=$(pwd);
    DATA_DIR="$(pwd)/frame_level_feature";
    TRAIN_DATA_PATTERN="hdfs://haruna/user/lab/open/youtube8m/data/frame_level/train/train*.tfrecord"
    VAL_DATA_PATTERN="hdfs://haruna/user/lab/open/youtube8m/data/frame_level/validate/validate-*.tfrecord"
    TRAIN_DIR="$ROOT_DIR/models/";
    mkdir $TRAIN_DIR;
    MODEL="LstmModel";
    LABEL_LOSS="CrossEntropyLoss";
    FEATURE_NAMES="rgb, audio";
    FEATURE_SIZES="1024, 128";
    DOWNLOAD_TMP_DIR="$ROOT_DIR/data_tmp";
    NUM_DOWNLOADERS=1;
    mkdir $DOWNLOAD_TMP_DIR;
    ENQUEUE_SIZE=4;
    PORT=9190;
    GPUS="0,1,2,3";
    bash -c "nohup tensorboard --logdir=$TRAIN_DIR --port=$PORT &";
    nvidia-smi;
    cd tf-youtube-8m/youtube-8m/;
    python -i train_hdfs.py
    --train_data_pattern="$TRAIN_DATA_PATTERN"
    --feature_names="$FEATURE_NAMES"
    --feature_sizes="$FEATURE_SIZES"
    --train_dir="$TRAIN_DIR"
    --frame_features=True
    --model="$MODEL"
    --base_learning_rate=0.001
    --regularization_penalty=10000.0
    --learning_rate_decay=0.8
    --learning_rate_decay_examples=5786881
    --batch_size=256
    --iterations=60
    --label_loss="$LABEL_LOSS"
    --gpus="$GPUS"
    --num_epochs=10
    --optimizer="AdamOptimizer"
    --disp_batches=100
    --export_model_steps=3000
    --moe_num_mixtures=4
    --start_new_model=True
    --data_tmp_dir=$DOWNLOAD_TMP_DIR
    --num_downloaders=$NUM_DOWNLOADERS
    --enqueue_size=$ENQUEUE_SIZE;
    python -i eval_hdfs.py
    --eval_data_pattern="$VAL_DATA_PATTERN"
    --frame_features=True
    --feature_names="$FEATURE_NAMES"
    --feature_sizes="$FEATURE_SIZES"
    --model="$MODEL"
    --label-loss="$LABEL_LOSS"
    --train_dir="$TRAIN_DIR"
    --gpus="$GPUS"
    --batch_size=1024
    --run_once=True
    --data_tmp_dir=$DOWNLOAD_TMP_DIR
    --num_downloaders=$NUM_DOWNLOADERS
    --enqueue_size=$ENQUEUE_SIZE;
    cd $ROOT_DIR;
    rm $DOWNLOAD_TMP_DIR; 
